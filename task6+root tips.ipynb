{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a6f00c-03db-49e6-a0b5-2f0d6dc64721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from patchify import patchify, unpatchify\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.measure import label\n",
    "\n",
    "def f1(y_true, y_pred, threshold=0.3):\n",
    "    y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
    "    TP = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    Pred_Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = TP / (Pred_Positives + tf.keras.backend.epsilon())\n",
    "    recall = TP / (Positives + tf.keras.backend.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "    \n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_metric(y_true, y_pred):\n",
    "    return f1(y_true, y_pred, threshold=0.3)\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Weighted binary cross-entropy to address class imbalance.\n",
    "    \"\"\"\n",
    "    # Define weights for foreground (root, shoot, seed) and background\n",
    "    weight_foreground = 10.0\n",
    "    weight_background = 1.0\n",
    "\n",
    "    # Compute weighted binary cross-entropy\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    weights = tf.where(y_true == 1, weight_foreground, weight_background)\n",
    "    loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_loss = loss * weights\n",
    "    return K.mean(weighted_loss)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + 1e-7) / (union + 1e-7)\n",
    "    return 1 - dice\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6fc810e-99cf-4b09-ac91-c8df749c3f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 17:11:12,666 - INFO - Enabled memory growth for GPU.\n",
      "2025-01-12 17:11:13,170 - INFO - Processing image: test_image_1.png\n",
      "2025-01-12 17:11:20,499 - INFO - Extracted Root Tip Coordinates for test_image_1.png: [[6.8935945822692455, 43.06671185212033, 0.057], [23.201511400948558, 54.59262703878216, 0.057], [28.18144573148486, 31.975736861181588, 0.057], [76.1201542320321, 39.47845523740485, 0.057], [142.5010371214885, 26.1040442189199, 0.057]]\n",
      "2025-01-12 17:11:20,500 - INFO - Processing image: test_image_10.png\n",
      "2025-01-12 17:11:28,595 - INFO - Extracted Root Tip Coordinates for test_image_10.png: [[14.689594174410292, 90.18015252416755, 0.057], [32.21997301644031, 115.79776799140708, 0.057], [71.46228895639742, 107.09744575725027, 0.057], [107.7560702287348, 96.73224704618688, 0.057], [135.57951554681915, 88.78380451127819, 0.057]]\n",
      "2025-01-12 17:11:28,596 - INFO - Processing image: test_image_11.png\n",
      "2025-01-12 17:11:36,677 - INFO - Extracted Root Tip Coordinates for test_image_11.png: [[7.8303098855917055, 117.19411600429645, 0.057], [34.537496156596355, 111.28648979591836, 0.057], [102.0562662674294, 116.01259076262083, 0.057], [114.92719941008224, 110.42719871106337, 0.057], [143.6186545405792, 143.88584532760473, 0.057]]\n",
      "2025-01-12 17:11:36,677 - INFO - Processing image: test_image_12.png\n",
      "2025-01-12 17:11:44,733 - INFO - Extracted Root Tip Coordinates for test_image_12.png: [[23.964075947105073, 76.72747277936962, 0.057], [45.13991583273767, 80.38076790830945, 0.057], [74.035555575411, 71.62360458452721, 0.057], [93.54949410293065, 73.55770200573065, 0.057], [124.85757130092922, 74.57847564469914, 0.057]]\n",
      "2025-01-12 17:11:44,734 - INFO - Processing image: test_image_13.png\n",
      "2025-01-12 17:11:52,777 - INFO - Extracted Root Tip Coordinates for test_image_13.png: [[18.763932987848463, 100.11570569280343, 0.057], [49.21425464617584, 88.67639312567131, 0.057], [70.22926536812008, 83.89658646616542, 0.057], [104.53948695496783, 95.8729559613319, 0.057], [123.78537687634024, 104.2510440386681, 0.057]]\n",
      "2025-01-12 17:11:52,782 - INFO - Processing image: test_image_14.png\n",
      "2025-01-12 17:12:00,981 - INFO - Extracted Root Tip Coordinates for test_image_14.png: [[6.489587683232035, 75.3573813104189, 0.057], [7.24039211655345, 90.07274113856069, 0.057], [16.786334197354307, 70.25534049409237, 0.057], [131.60578360743656, 14.025480128893662, 0.057], [132.6247324812299, 9.72902470461869, 0.057]]\n",
      "2025-01-12 17:12:00,982 - INFO - Processing image: test_image_15.png\n",
      "2025-01-12 17:12:08,857 - INFO - Extracted Root Tip Coordinates for test_image_15.png: [[7.93756766178048, 123.4776820622986, 0.057], [8.95651653557383, 63.703245972073034, 0.057], [4.290803271362174, 76.70002363050483, 0.057], [20.057696371111906, 94.10066809881847, 0.057], [147.47993448337505, 132.60764983888294, 0.057]]\n",
      "2025-01-12 17:12:08,857 - INFO - Processing image: test_image_16.png\n",
      "2025-01-12 17:12:16,628 - INFO - Extracted Root Tip Coordinates for test_image_16.png: [[13.992667798427448, 134.1651149301826, 0.057], [22.302174588992134, 46.78595273899033, 0.057], [103.73534113652607, 49.47123737916219, 0.057], [132.3629322730522, 47.05448120300751, 0.057], [143.88902233738384, 127.77413748657357, 0.057]]\n",
      "2025-01-12 17:12:16,630 - INFO - Processing image: test_image_17.png\n",
      "2025-01-12 17:12:24,602 - INFO - Extracted Root Tip Coordinates for test_image_17.png: [[16.02983720514653, 59.481770773638964, 0.057], [45.46157416011437, 62.49036676217764, 0.057], [73.7138972480343, 66.35856160458452, 0.057], [104.91475500357397, 64.6930888252149, 0.057], [124.42869353109363, 62.16801719197707, 0.057]]\n",
      "2025-01-12 17:12:24,603 - INFO - Processing image: test_image_18.png\n",
      "2025-01-12 17:12:32,596 - INFO - Extracted Root Tip Coordinates for test_image_18.png: [[14.104889792634966, 115.58294522019334, 0.057], [16.679076421165533, 58.38638238453276, 0.057], [50.57253369681803, 83.25211815252416, 0.057], [106.88286619592421, 96.62483566058002, 0.057], [134.39448578834467, 96.73224704618688, 0.057]]\n",
      "2025-01-12 17:12:32,600 - INFO - Processing image: test_image_2.png\n",
      "2025-01-12 17:12:40,567 - INFO - Extracted Root Tip Coordinates for test_image_2.png: [[6.475674528301886, 82.44569996393797, 0.057], [48.92850471698113, 33.058754417598266, 0.057], [67.97785159651669, 72.38439451857194, 0.057], [100.74272822931785, 101.86510133429498, 0.057], [120.0642086357039, 90.50556292823656, 0.057]]\n",
      "2025-01-12 17:12:40,568 - INFO - Processing image: test_image_3.png\n",
      "2025-01-12 17:12:48,324 - INFO - Extracted Root Tip Coordinates for test_image_3.png: [[20.83323304775793, 36.21835179153094, 0.057], [76.01004675537732, 31.495224755700328, 0.057], [103.35237267590229, 33.775355048859936, 0.057], [131.95244558877144, 31.92953528773073, 0.057], [137.25685681735328, 21.88610423452769, 0.057]]\n",
      "2025-01-12 17:12:48,325 - INFO - Processing image: test_image_4.png\n",
      "2025-01-12 17:12:56,281 - INFO - Extracted Root Tip Coordinates for test_image_4.png: [[22.042999181520553, 44.342043305665825, 0.057], [50.90804101491452, 43.42179790689282, 0.057], [76.44459976355037, 39.361891735835435, 0.057], [99.79854665332847, 43.09700541320823, 0.057], [131.99207157148055, 34.165211836881994, 0.057]]\n",
      "2025-01-12 17:12:56,283 - INFO - Processing image: test_image_5.png\n",
      "2025-01-12 17:13:04,149 - INFO - Extracted Root Tip Coordinates for test_image_5.png: [[21.769578737300435, 44.001393939393935, 0.057], [47.18685014513788, 40.971090909090904, 0.057], [74.50905624092887, 31.988406926406928, 0.057], [101.50470210449926, 39.5641645021645, 0.057], [133.61645827285923, 38.75247619047619, 0.057]]\n",
      "2025-01-12 17:13:04,149 - INFO - Processing image: test_image_6.png\n",
      "2025-01-12 17:13:12,093 - INFO - Extracted Root Tip Coordinates for test_image_6.png: [[21.357295949872864, 44.655128390596744, 0.057], [43.47861814384308, 52.955309222423146, 0.057], [71.48442998547038, 52.90105967450271, 0.057], [100.30753205593896, 51.49057142857143, 0.057], [128.69474600435888, 41.996900542495474, 0.057]]\n",
      "2025-01-12 17:13:12,094 - INFO - Processing image: test_image_7.png\n",
      "2025-01-12 17:13:20,127 - INFO - Extracted Root Tip Coordinates for test_image_7.png: [[20.968316448801744, 50.116288816503804, 0.057], [47.22103976034859, 37.79272747014115, 0.057], [75.43454738562092, 32.255268186753526, 0.057], [105.17310947712419, 49.627689467969596, 0.057], [131.75263017429197, 53.916505971769816, 0.057]]\n",
      "2025-01-12 17:13:20,128 - INFO - Processing image: test_image_8.png\n",
      "2025-01-12 17:13:28,239 - INFO - Extracted Root Tip Coordinates for test_image_8.png: [[9.48275, 133.3712485549133, 0.057], [30.740017441860463, 137.0562196531792, 0.057], [80.44931976744185, 94.89581502890174, 0.057], [89.33376744186046, 119.39003468208092, 0.057], [131.08522093023257, 63.19422543352601, 0.057]]\n",
      "2025-01-12 17:13:28,239 - INFO - Processing image: test_image_9.png\n",
      "2025-01-12 17:13:36,249 - INFO - Extracted Root Tip Coordinates for test_image_9.png: [[23.427978734810576, 58.17155961331901, 0.057], [47.60596300929235, 55.37886358754027, 0.057], [75.59023749106504, 62.09207518796992, 0.057], [106.09416887062186, 50.86758539205155, 0.057], [131.9340545032166, 60.74943286788399, 0.057]]\n",
      "2025-01-12 17:13:36,251 - INFO - Saved root tip coordinates to root_tip_coordinates.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"pipeline_log.txt\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess the input image.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "def extract_petri_dish(image):\n",
    "    \"\"\"Extract the largest contour assumed to be the Petri dish.\"\"\"\n",
    "    _, thresholded = cv2.threshold(image, 57, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        logging.warning(\"No contours detected for Petri dish.\")\n",
    "        return image, np.ones_like(image)\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "def predict_root_mask(image, model, patch_size=128, stride=64, batch_size=16):\n",
    "    \"\"\"Predict root mask using a patch-based model with smaller batches.\"\"\"\n",
    "    h, w = image.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = image[y:y+patch_size, x:x+patch_size]\n",
    "            patch_rgb = np.stack([patch] * 3, axis=-1)\n",
    "            patches.append(patch_rgb)\n",
    "            positions.append((y, x))\n",
    "\n",
    "    patches = np.array(patches) / 255.0\n",
    "    predictions = []\n",
    "    for i in range(0, len(patches), batch_size):\n",
    "        batch = patches[i:i + batch_size]\n",
    "        batch_predictions = model.predict(batch, verbose=0)\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "    reconstructed = np.zeros((h, w), dtype=np.float32)\n",
    "    counts = np.zeros((h, w), dtype=np.float32)\n",
    "    for pred, (y, x) in zip(predictions, positions):\n",
    "        pred = pred[..., 0]\n",
    "        reconstructed[y:y+patch_size, x:x+patch_size] += pred\n",
    "        counts[y:y+patch_size, x:x+patch_size] += 1\n",
    "    return (reconstructed / np.maximum(counts, 1) > 0.3).astype(np.uint8)\n",
    "\n",
    "def connect_roots(mask):\n",
    "    \"\"\"Dilate the mask to connect fragmented roots.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    return cv2.dilate(mask, kernel, iterations=27)\n",
    "\n",
    "def filter_and_select_largest_objects(mask, min_area=500, max_objects=5):\n",
    "    \"\"\"Filter and retain the largest root components.\"\"\"\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    valid_objects = [(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] >= min_area]\n",
    "    largest_objects = sorted(valid_objects, key=lambda x: x[1], reverse=True)[:max_objects]\n",
    "\n",
    "    filtered_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for obj_id, _ in largest_objects:\n",
    "        filtered_mask[labels == obj_id] = 255\n",
    "    return filtered_mask, largest_objects\n",
    "\n",
    "def measure_bounding_boxes(filtered_mask):\n",
    "    \"\"\"Measure roots with bounding boxes.\"\"\"\n",
    "    contours, _ = cv2.findContours(filtered_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "    return bounding_boxes\n",
    "\n",
    "def find_lowest_point(mask, bounding_box):\n",
    "    \"\"\"Find the lowest point in a bounding box.\"\"\"\n",
    "    x, y, w, h = bounding_box\n",
    "    roi = mask[y:y+h, x:x+w]\n",
    "    coordinates = np.column_stack(np.where(roi > 0))\n",
    "    if len(coordinates) == 0:\n",
    "        return None\n",
    "    lowest_local = coordinates[np.argmax(coordinates[:, 0])]\n",
    "    return lowest_local + [y, x]\n",
    "\n",
    "def convert_to_mm(pixel_coords, image_shape, plate_size_mm=150):\n",
    "    \"\"\"Convert pixel coordinates to mm-space.\"\"\"\n",
    "    h, w = image_shape\n",
    "    conversion_factor_x = plate_size_mm / w\n",
    "    conversion_factor_y = plate_size_mm / h\n",
    "    return np.array([pixel_coords[1] * conversion_factor_x, pixel_coords[0] * conversion_factor_y])\n",
    "\n",
    "# Directory containing images\n",
    "input_dir = \"kaggle_test\"\n",
    "output_file = \"root_tip_coordinates.json\"\n",
    "model_path = \"232430_unet_model_128px_v8md.keras\"\n",
    "plate_position_robot = np.array([0.10775, 0.088 - 0.026, 0.057])  # Adjust based on your setup\n",
    "\n",
    "# Register custom objects for model deserialization\n",
    "custom_objects = {\n",
    "    \"combined_loss\": combined_loss,\n",
    "    \"f1_metric\": f1_metric\n",
    "}\n",
    "\n",
    "# Limit GPU memory growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        logging.info(\"Enabled memory growth for GPU.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error enabling memory growth for GPU: {e}\")\n",
    "\n",
    "# Load the model with custom objects\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "# Process all images in the directory\n",
    "all_root_tip_coords = {}\n",
    "\n",
    "for image_name in sorted(os.listdir(input_dir)):\n",
    "    if not image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(input_dir, image_name)\n",
    "    logging.info(f\"Processing image: {image_name}\")\n",
    "\n",
    "    try:\n",
    "        # Process the image and extract root tip coordinates\n",
    "        image = preprocess_image(image_path)\n",
    "        petri_dish = extract_petri_dish(image)\n",
    "        predicted_mask = predict_root_mask(petri_dish, model)\n",
    "        connected_mask = connect_roots(predicted_mask)\n",
    "        filtered_mask, _ = filter_and_select_largest_objects(connected_mask, min_area=500, max_objects=5)\n",
    "        bounding_boxes = measure_bounding_boxes(filtered_mask)\n",
    "\n",
    "        root_tip_coords = []\n",
    "        for box in bounding_boxes:\n",
    "            point = find_lowest_point(filtered_mask, box)\n",
    "            if point is not None:\n",
    "                mm_coords = convert_to_mm(point, petri_dish.shape)\n",
    "                robot_coords = np.append(mm_coords, 0) + plate_position_robot\n",
    "                root_tip_coords.append(robot_coords.tolist())  # Convert to list for JSON serialization\n",
    "\n",
    "        all_root_tip_coords[image_name] = root_tip_coords\n",
    "        logging.info(f\"Extracted Root Tip Coordinates for {image_name}: {root_tip_coords}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "# Save the root tip coordinates to a JSON file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(all_root_tip_coords, f, indent=4)\n",
    "    logging.info(f\"Saved root tip coordinates to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ade728-1bf1-4402-9e52-d3922dd29e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
